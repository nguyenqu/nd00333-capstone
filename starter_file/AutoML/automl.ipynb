{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Automated ML\n",
        "\n",
        "## Import libraries for Azure Machine Learning SDK"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "import joblib\n",
        "import logging\n",
        "import sklearn\n",
        "import pkg_resources\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from sklearn import datasets\n",
        "\n",
        "import azureml.core\n",
        "from azureml.core import Workspace, Experiment, Model\n",
        "\n",
        "from azureml.core.webservice import AciWebservice, Webservice\n",
        "from azureml.core.webservice import LocalWebservice\n",
        "from azureml.core.conda_dependencies import CondaDependencies\n",
        "\n",
        "from azureml.train.automl import AutoMLConfig\n",
        "\n",
        "from azureml.pipeline.steps import AutoMLStep\n",
        "from azureml.contrib.pipeline.steps import ParallelRunStep\n",
        "from azureml.contrib.pipeline.steps import ParallelRunConfig\n",
        "\n",
        "# Check core SDK version number\n",
        "print(\"SDK version:\", azureml.core.VERSION)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "SDK version: 1.49.0\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1686295199027
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize Workspace\n",
        "Initialize a workspace object from persisted configuration. Make sure the config file is present at .\\config.json"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "ws = Workspace.from_config()\n",
        "\n",
        "print('Workspace name:\\t\\t'  + ws.name,\n",
        "      'Resource group:\\t\\t'  + ws.resource_group,\n",
        "      'Azure region:\\t\\t'    + ws.location,\n",
        "      'Subscription id:\\t' + ws.subscription_id, sep='\\n')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Workspace name:\t\tquick-starts-ws-235359\nResource group:\t\taml-quickstarts-235359\nAzure region:\t\twestus2\nSubscription id:\td7f39349-a66b-446e-aba6-0053c2cf1c11\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1686295200090
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create an Azure ML experiment"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Name for experiment\n",
        "experiment_name = 'automl-heart-failure-experiment'\n",
        "\n",
        "experiment=Experiment(ws, experiment_name)\n",
        "run = experiment.start_logging()\n",
        "\n",
        "experiment"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 3,
          "data": {
            "text/plain": "Experiment(Name: automl-heart-failure-experiment,\nWorkspace: quick-starts-ws-235359)",
            "text/html": "<table style=\"width:100%\"><tr><th>Name</th><th>Workspace</th><th>Report Page</th><th>Docs Page</th></tr><tr><td>automl-heart-failure-experiment</td><td>quick-starts-ws-235359</td><td><a href=\"https://ml.azure.com/experiments/id/51ebcfa0-21e0-4eb4-bc74-0e08688da3bb?wsid=/subscriptions/d7f39349-a66b-446e-aba6-0053c2cf1c11/resourcegroups/aml-quickstarts-235359/workspaces/quick-starts-ws-235359&amp;tid=660b3398-b80e-49d2-bc5b-ac1dc93b5254\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.experiment.Experiment?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1686295201865
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create or Attach an AmlCompute Target\n",
        "We will need to create a compute target for our AutoML run. We will use ***vm_size = Standard_DS3_v2*** in our provisioning configuration and select ***max_nodes*** to be no greater than 4."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "# Name for the CPU cluster\n",
        "amlcompute_cluster_name = \"automl-cpu-compute-cluster\"\n",
        "\n",
        "# Verify that cluster does not exist already\n",
        "try:\n",
        "    amlcompute_target = ComputeTarget(workspace=ws, name=amlcompute_cluster_name)\n",
        "    print('Found existing cluster, use it.')\n",
        "except ComputeTargetException:\n",
        "    amlcompute_config = AmlCompute.provisioning_configuration(vm_size='Standard_DS3_v2', max_nodes=4)\n",
        "    amlcompute_target = ComputeTarget.create(ws, amlcompute_cluster_name, amlcompute_config)\n",
        "\n",
        "amlcompute_target.wait_for_completion(show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Found existing cluster, use it.\nSucceeded\nAmlCompute wait for completion finished\n\nMinimum number of nodes requested have been provisioned\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1686295202483
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "compute_targets = ws.compute_targets\n",
        "\n",
        "for i, key in enumerate(compute_targets):\n",
        "    print(f\"{i+1}. Compute target\\n\\tname: {compute_targets[key].name}\\n\\tType: {compute_targets[key].type}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "1. Compute target\n\tname: notebook235359\n\tType: ComputeInstance\n2. Compute target\n\tname: automl-cpu-compute-cluster\n\tType: AmlCompute\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1686295202981
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For a more detailed view of current AmlCompute status, use get_status().\n",
        "print(amlcompute_target.get_status().serialize())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "{'currentNodeCount': 0, 'targetNodeCount': 0, 'nodeStateCounts': {'preparingNodeCount': 0, 'runningNodeCount': 0, 'idleNodeCount': 0, 'unusableNodeCount': 0, 'leavingNodeCount': 0, 'preemptedNodeCount': 0}, 'allocationState': 'Steady', 'allocationStateTransitionTime': '2023-06-09T06:30:34.422000+00:00', 'errors': None, 'creationTime': '2023-06-09T06:30:29.716756+00:00', 'modifiedTime': '2023-06-09T06:30:36.879219+00:00', 'provisioningState': 'Succeeded', 'provisioningStateTransitionTime': None, 'scaleSettings': {'minNodeCount': 0, 'maxNodeCount': 4, 'nodeIdleTimeBeforeScaleDown': 'PT1800S'}, 'vmPriority': 'Dedicated', 'vmSize': 'STANDARD_DS3_V2'}\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1686295203674
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset\n",
        "\n",
        "### Overview\n",
        "The dataset used for this project is the ***Heart Failure Clinical Records*** dataset, which can be found [here](https://archive.ics.uci.edu/ml/datasets/Heart+failure+clinical+records) in the UCI Machine Learning Repository. \n",
        "\n",
        "This dataset contains the medical records of 299 patients who had heart failure, collected during their follow-up period, where each patient profile has 13 clinical features.\n",
        "\n",
        "The task we are concerned with is to predict whether the patient died during the follow-up period. We will target the DEATH_EVENT column and since it is a boolean variable, the task is binary classification."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.dataset import Dataset\n",
        "\n",
        "# Try to load the dataset from the Workspace. Otherwise, create it from the file\n",
        "description_text = \"Health Failure dataset from UCI ML-Repository for mortality prediction for the Capstone Project.\"\n",
        "key = \"HealthFailure Dataset\"      # the key to match the dataset name\n",
        "\n",
        "# dataset_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00519/heart_failure_clinical_records_dataset.csv\"\n",
        "dataset_url = \"https://github.com/nguyenqu/nd00333-capstone/tree/master/starter_file/heart_failure_clinical_records_dataset.csv\"\n",
        "# dataset_url = \"./../heart_failure_clinical_records_dataset.csv\"\n",
        "\n",
        "if key in ws.datasets.keys():\n",
        "    dataset = ws.datasets[key]\n",
        "    print(\"The Dataset was found!\")\n",
        "else:\n",
        "    dataset = Dataset.Tabular.from_delimited_files(dataset_url) # Create AML Dataset and register it into Workspace\n",
        "    dataset = dataset.register(workspace=ws, name=key, description=description_text) # Register Dataset in Workspace\n",
        "\n",
        "df = dataset.to_pandas_dataframe()"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "DatasetValidationError",
          "evalue": "DatasetValidationError:\n\tMessage: Failed to validate the data.\nThe Dataflow produced no records.| session_id=c139d69a-1571-4f49-88ff-0be7372668a4\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"Failed to validate the data.\\nThe Dataflow produced no records.| session_id=c139d69a-1571-4f49-88ff-0be7372668a4\"\n    }\n}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mDataflowValidationError\u001b[0m                   Traceback (most recent call last)",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/data/dataset_error_handling.py:66\u001b[0m, in \u001b[0;36m_validate_has_data\u001b[0;34m(dataflow, error_message)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 66\u001b[0m     \u001b[43mdataflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverify_has_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (dataprep()\u001b[38;5;241m.\u001b[39mapi\u001b[38;5;241m.\u001b[39mdataflow\u001b[38;5;241m.\u001b[39mDataflowValidationError,\n\u001b[1;32m     68\u001b[0m         dataprep()\u001b[38;5;241m.\u001b[39mapi\u001b[38;5;241m.\u001b[39merrorhandlers\u001b[38;5;241m.\u001b[39mExecutionError) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/dataprep/api/_loggerfactory.py:273\u001b[0m, in \u001b[0;36mtrack.<locals>.monitor.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 273\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/dataprep/api/dataflow.py:880\u001b[0m, in \u001b[0;36mDataflow.verify_has_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39m_to_pyrecords()) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 880\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DataflowValidationError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe Dataflow produced no records.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mDataflowValidationError\u001b[0m: \nError Code: Empty\nError Message: The Dataflow produced no records.| session_id=c139d69a-1571-4f49-88ff-0be7372668a4",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mDatasetValidationError\u001b[0m                    Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[7], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe Dataset was found!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 15\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTabular\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_delimited_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_url\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Create AML Dataset and register it into Workspace\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mregister(workspace\u001b[38;5;241m=\u001b[39mws, name\u001b[38;5;241m=\u001b[39mkey, description\u001b[38;5;241m=\u001b[39mdescription_text) \u001b[38;5;66;03m# Register Dataset in Workspace\u001b[39;00m\n\u001b[1;32m     18\u001b[0m df \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mto_pandas_dataframe()\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/data/_loggerfactory.py:132\u001b[0m, in \u001b[0;36mtrack.<locals>.monitor.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _LoggerFactory\u001b[38;5;241m.\u001b[39mtrack_activity(logger, func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, activity_type, custom_dimensions) \u001b[38;5;28;01mas\u001b[39;00m al:\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 132\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    134\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(al, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactivity_info\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124merror_code\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/data/dataset_factory.py:366\u001b[0m, in \u001b[0;36mTabularDatasetFactory.from_delimited_files\u001b[0;34m(path, validate, include_path, infer_column_types, set_column_types, separator, header, partition_format, support_multi_line, empty_as_string, encoding)\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    357\u001b[0m     dataflow \u001b[38;5;241m=\u001b[39m dataprep()\u001b[38;5;241m.\u001b[39mread_csv(path,\n\u001b[1;32m    358\u001b[0m                                    verify_exists\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    359\u001b[0m                                    include_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    363\u001b[0m                                    quoting\u001b[38;5;241m=\u001b[39msupport_multi_line,\n\u001b[1;32m    364\u001b[0m                                    encoding\u001b[38;5;241m=\u001b[39mencoding)\n\u001b[0;32m--> 366\u001b[0m dataflow \u001b[38;5;241m=\u001b[39m \u001b[43m_transform_and_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataflow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartition_format\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[43m    \u001b[49m\u001b[43minfer_column_types\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_is_inference_required\u001b[49m\u001b[43m(\u001b[49m\u001b[43mset_column_types\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m infer_column_types:\n\u001b[1;32m    371\u001b[0m     column_types_builder \u001b[38;5;241m=\u001b[39m dataflow\u001b[38;5;241m.\u001b[39mbuilders\u001b[38;5;241m.\u001b[39mset_column_types()\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/data/dataset_factory.py:1173\u001b[0m, in \u001b[0;36m_transform_and_validate\u001b[0;34m(dataflow, partition_format, include_path, validate, infer_column_types)\u001b[0m\n\u001b[1;32m   1171\u001b[0m     dataflow \u001b[38;5;241m=\u001b[39m dataflow\u001b[38;5;241m.\u001b[39mdrop_columns(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPath\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validate:\n\u001b[0;32m-> 1173\u001b[0m     \u001b[43m_validate_has_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataflow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mFailed to validate the data.\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1174\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m infer_column_types:\n\u001b[1;32m   1175\u001b[0m     _validate_has_data(dataflow, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFailed to infer column type.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1176\u001b[0m                                  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mif data is inaccessible, please set infer_column_types to False.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/data/dataset_error_handling.py:69\u001b[0m, in \u001b[0;36m_validate_has_data\u001b[0;34m(dataflow, error_message)\u001b[0m\n\u001b[1;32m     66\u001b[0m     dataflow\u001b[38;5;241m.\u001b[39mverify_has_data()\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (dataprep()\u001b[38;5;241m.\u001b[39mapi\u001b[38;5;241m.\u001b[39mdataflow\u001b[38;5;241m.\u001b[39mDataflowValidationError,\n\u001b[1;32m     68\u001b[0m         dataprep()\u001b[38;5;241m.\u001b[39mapi\u001b[38;5;241m.\u001b[39merrorhandlers\u001b[38;5;241m.\u001b[39mExecutionError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m---> 69\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DatasetValidationError(error_message \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m e\u001b[38;5;241m.\u001b[39mcompliant_message, exception\u001b[38;5;241m=\u001b[39me)\n",
            "\u001b[0;31mDatasetValidationError\u001b[0m: DatasetValidationError:\n\tMessage: Failed to validate the data.\nThe Dataflow produced no records.| session_id=c139d69a-1571-4f49-88ff-0be7372668a4\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"Failed to validate the data.\\nThe Dataflow produced no records.| session_id=c139d69a-1571-4f49-88ff-0be7372668a4\"\n    }\n}"
          ]
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1686295207474
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1686295209184
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1686295209228
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prepare the datasets for the Automation"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from azureml.data.dataset_factory import TabularDatasetFactory\n",
        "\n",
        "# Split the dataset into training and testing datasets\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, shuffle=True)\n",
        "\n",
        "if \"data\" not in os.listdir():\n",
        "    os.mkdir(\"./data\")\n",
        "\n",
        "# Save training data to csv file\n",
        "train_df.to_csv(\"./data/train_data.csv\", index=False)\n",
        "\n",
        "# Read saved training data and create a dataset in Azure ML\n",
        "data_store = ws.get_default_datastore()\n",
        "data_store.upload(src_dir=\"./data\", target_path=\"automl_training_data\")\n",
        "train_ds = TabularDatasetFactory.from_delimited_files(path=[(data_store, 'automl_training_data/train_data.csv')])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1686295209278
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Review the Training Dataset Result"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds.take(5).to_pandas_dataframe()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1686295209325
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AutoML Configuration\n",
        "\n",
        "- ***experiment_timeout_minutes = 20***: Specifies how long (in minutes) our experiment should run. In previous projects we could not set more than 30 minutes. We could use more in this project, but it's not needed for such a small training set. To reduce the time taken to train, experiment_timeout_minutes of 20 was chosen.\n",
        "\n",
        "- ***max_concurrent_iterations = 4***: The maximum number of iterations that could be run in parallel. It is recommended to create a dedicated cluster per experiment and adjust the number of max_concurrent_iterations of your experiment to the number of nodes in the cluster. In this way you use all nodes of the cluster at the same time with the desired number of concurrent child runs/iterations. So I set the value to 4.\n",
        "\n",
        "- ***primary_metric = 'accuracy'***: The metric that is optimized by automated machine learning for model selection. We have set the \"accuracy\"/\"AUC_weighted\".\n",
        "\n",
        "\n",
        "\n",
        "- ***compute_target = amlcompute_target*** : The compute target with specific vm_size and max_nodes used to run the experiment. The local compute was chosen as this may be slower but generally provides better results.\n",
        "\n",
        "- ***task = 'classification'*** : We have a classification task to do, we want to predict whether the person will have heart failure or not. In other words, we're trying to predict the DEATH_EVENT.\n",
        "\n",
        "- ***training_data = train_ds*** : The data (80% of the total dataset) on which used in the experiment to train the algorithm.\n",
        "\n",
        "- ***label_column_name = \"DEATH_EVENT\"*** : The target variable to predict.\n",
        "\n",
        "- ***path = project_folder*** : The full path to the Azure ML folder of the project './capstone-project'.\n",
        "\n",
        "- ***enable_early_stopping = True*** : Early stopping is enabled so if a run is not performing well, it can stop early, again to save time and if not performing well continuing seems uncessary.\n",
        "\n",
        "- ***featurization = 'auto'*** : indicator of whether the featurization step should be performed automatically or not, or whether a custom featurization should be used. I used \"Auto\" so the featurization step should be automatic.\n",
        "\n",
        "- ***debug_log = \"automl_errors.log\"*** : The debug information are written to the automl_errors.log.\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "project_folder = './capstone-project'\n",
        "\n",
        "# Define automl settings\n",
        "automl_settings = {\n",
        "    \"experiment_timeout_minutes\": 20,\n",
        "    \"max_concurrent_iterations\": 4,\n",
        "    \"primary_metric\" : 'AUC_weighted'\n",
        "}\n",
        "\n",
        "# Define automl configuration settings\n",
        "automl_config = AutoMLConfig(compute_target = amlcompute_target,\n",
        "                             task = \"classification\",\n",
        "                             training_data = train_ds,\n",
        "                             label_column_name = \"DEATH_EVENT\",   \n",
        "                             path = project_folder,\n",
        "                             enable_early_stopping = True,\n",
        "                             featurization = 'auto',\n",
        "                             debug_log = \"automl_errors.log\",\n",
        "                             **automl_settings\n",
        "                            )"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1686295209357
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Submit the experiment to the compute target \n",
        "automl_run = experiment.submit(automl_config, show_output=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1686295209391
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "automl_run.wait_for_completion(show_output=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1686295209426
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Details\n",
        "\n",
        "OPTIONAL: Write about the different models trained and their performance. Why do you think some models did better than others?\n",
        "\n",
        "Use the `RunDetails` widget to show the different experiments."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.widgets import RunDetails\n",
        "\n",
        "RunDetails(automl_run).show()\n",
        "for children_run in automl_run.get_children():\n",
        "    print('-----------------------------------')\n",
        "    print(children_run)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1686295209454
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Best Model\n",
        "\n",
        "Get the best model from the automl experiments and display all the properties of the model."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# get the best model\n",
        "best_run, best_model = automl_run.get_output()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1686295209487
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_model"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1686295209518
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "\n",
        "# parameter details of the best model\n",
        "def print_model(model, prefix=\"\"):\n",
        "    for step in model.steps:\n",
        "        print(prefix + step[0])\n",
        "        if hasattr(step[1], 'estimators') and hasattr(step[1], 'weights'):\n",
        "            pprint({'estimators': list(\n",
        "                e[0] for e in step[1].estimators), 'weights': step[1].weights})\n",
        "            print()\n",
        "            for estimator in step[1].estimators:\n",
        "                print_model(estimator[1], estimator[0] + ' - ')\n",
        "        else:\n",
        "            pprint(step[1].get_params())\n",
        "            print()\n",
        "\n",
        "print_model(best_model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1686295209550
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_run"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1686295209589
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_run.get_tags()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1686295209623
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_run.get_metrics()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1686295209653
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for primary_metric in best_run.get_metrics():\n",
        "    metric=best_run.get_metrics()[primary_metric]\n",
        "    print(primary_metric,metric)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1686295209688
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_run.get_metrics(name='AUC_weighted')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1686295209721
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_run.get_details()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1686295209759
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_run.get_properties()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1686295209787
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test the best model"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Split into x and y tests\n",
        "y_test = test_df['DEATH_EVENT']\n",
        "x_test = test_df.drop(['DEATH_EVENT'],axis=1)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1686295209824
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Test the best model and create a confusion matrix\n",
        "ypred = best_model.predict(x_test)\n",
        "cmatrix = confusion_matrix(y_test, ypred)\n",
        "\n",
        "# Visualize the confusion matrix\n",
        "##pd.DataFrame(cmatrix)\n",
        "pd.DataFrame(cmatrix).style.background_gradient(cmap='Blues', low=0, high=0.9)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1686295209855
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save the best model"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "best_run.get_file_names()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1686295209893
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_run.register_model(model_name='best_run_automl', model_path='./outputs/')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1686295209926
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.automl.core.shared import constants\n",
        "\n",
        "# create inference folder\n",
        "inference_folder = 'inference'\n",
        "if inference_folder not in os.listdir():\n",
        "    os.mkdir(inference_folder)\n",
        "\n",
        "# Save the best model, scoring script, and conda env files in inference folder\n",
        "best_run.download_file('outputs/scoring_file_v_1_0_0.py', inference_folder + '/best_automl_score.py')\n",
        "best_run.download_file('outputs/model.pkl', inference_folder + '/best_automl_model.pkl')\n",
        "\n",
        "best_run.download_file('outputs/conda_env_v_1_0_0.yml', inference_folder + '/automl_conda_env.yml')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1686293850771
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save the environment"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.environment import Environment\n",
        "\n",
        "# get the list of environments\n",
        "Environment.list(workspace=ws).keys()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1686293850814
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# save the environment\n",
        "my_env = Environment.get(workspace=ws, name=\"AzureML-AutoML\")\n",
        "my_env.save_to_directory('env', overwrite=True)\n",
        "\n",
        "my_env"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1686293850852
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Deployment\n",
        "\n",
        "Remember you have to deploy only one of the two models you trained but you still need to register both the models. Perform the steps in the rest of this notebook only if you wish to deploy this model.\n",
        "\n",
        "Register the model, create an inference config and deploy the model as a web service."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Register the model\n",
        "from azureml.core.resource_configuration import ResourceConfiguration\n",
        "\n",
        "model_name = best_run.properties['model_name']\n",
        "local_file = inference_folder + '/best_automl_model.pkl'\n",
        "\n",
        "run_id = best_run.id\n",
        "experiment_name = best_run.experiment.name\n",
        "\n",
        "model = Model.register(workspace = ws,\n",
        "                       model_name = model_name,                        # Name of the registered model in your workspace.\n",
        "                       model_path = local_file,                        # Local file to upload and register as a model.\n",
        "                       model_framework = Model.Framework.SCIKITLEARN,  # Framework used to create the model.\n",
        "                       model_framework_version = sklearn.__version__,  # Version of scikit-learn used to create the model.\n",
        "                       description = 'Best autoML model to predict motality caused by heart failure.',\n",
        "                       tags={'area': 'heart-failure', 'type': 'classification'})\n",
        "\n",
        "print('Model name:', model.name)\n",
        "print('Model id:', model.id)\n",
        "print('Model version:', model.version)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1686292250000
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create inference configuration\n",
        "from azureml.core.environment import Environment\n",
        "from azureml.core.model import InferenceConfig\n",
        "\n",
        "####env = Environment.from_conda_specification(name=\"my_env\", file_path=inference_folder + '/automl_conda_env.yml')\n",
        "####env\n",
        "#### Siehe Oben my_env --> Ist es gleich?\n",
        "####inference_config = InferenceConfig(entry_script=inference_folder + '/best_automl_score.py', environment=env)\n",
        "\n",
        "inference_config = InferenceConfig(entry_script=inference_folder + '/best_automl_score.py', environment=my_env)\n",
        "\n",
        "# display the environment file \n",
        "with open(inference_folder + '/automl_conda_env.yml') as file:\n",
        "    env_file = file.read()\n",
        "    print(env_file)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1686292250032
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Deployment\n",
        "from azureml.core.webservice import AciWebservice\n",
        "\n",
        "# define deployment configuration\n",
        "aci_deployment_config = AciWebservice.deploy_configuration(cpu_cores=1,\n",
        "                                                           memory_gb=1,\n",
        "                                                           tags={'area': \"heart-failure\", 'type': \"classification\"},\n",
        "                                                           description=\"Predict heart failure mortality using classification model\",\n",
        "                                                           auth_enabled=True,\n",
        "                                                           enable_app_insights=True)\n",
        "\n",
        "# deploy model as webservice using Azure Container Instance(ACI)\n",
        "aci_service = Model.deploy(workspace = ws, \n",
        "                           name = \"aci-heart-failure-deploy\", \n",
        "                           models = [model], \n",
        "                           inference_config = inference_config, \n",
        "                           deployment_config = aci_deployment_config, \n",
        "                           overwrite=True)\n",
        "\n",
        "aci_service.wait_for_deployment(show_output=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1686292250066
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get the active api endpoint for scoring\n",
        "print(f\"Service State: {aci_service.state}\\n\")\n",
        "print(f\"Scoring URI:   {aci_service.scoring_uri}\\n\")\n",
        "print(f\"Swagger URI:   {aci_service.swagger_uri}\\n\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1686292250098
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Consuming the model\n",
        "Send a request to the web service you deployed to test it."
      ],
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1598431657736
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Send a request to the web service\n",
        "import json\n",
        "import requests\n",
        "\n",
        "'''\n",
        "input_data = json.dumps({\n",
        "    \"data\": [\n",
        "            [75.0, 0.0, 582.0, 0.0, 20.0, 1.0, 265000.0, 1.9, 130.0, 1.0, 0.0, 4.0],\n",
        "            [80.0, 1.0, 123.0, 0.0, 35.0, 1.0, 388000.0, 9.4, 133.0, 1.0, 1.0, 10.0],\n",
        "            [62.0, 0.0, 61.0, 1.0, 38.0, 1.0, 155000.0, 1.1, 143.0, 1.0, 1.0, 270.0],\n",
        "            [50.0, 1.0, 111.0, 0.0, 20.0, 0.0, 210000.0, 1.9, 137.0, 1.0, 0.0, 7.0]\n",
        "        ]\n",
        "    })\n",
        "'''\n",
        "\n",
        "# 4 sets of data to score, so we get two results back\n",
        "test_sample = test_df.sample(n=4)\n",
        "labels = test_sample.pop('DEATH_EVENT')\n",
        "\n",
        "\n",
        "# Convert to JSON string\n",
        "input_data = json.dumps({\"data\": test_sample.to_dict(orient='records')})\n",
        "with open(\"input_data.json\", 'w') as _f:\n",
        "    _f.write(input_data)\n",
        "\n",
        "print(input_data)\n",
        "\n",
        "response = requests.post(aci_service.scoring_uri, data=input_data, headers={'Content-Type':'application/json'})"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1686292250124
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Predictions from Service: {response.json()}\\n\")\n",
        "print(f\"Data Labels: {labels.tolist()}\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1686292250165
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Print the logs of the web service and delete the service"
      ],
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1598432765711
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the log of the webservice\n",
        "print(aci_service.get_logs())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1686292250199
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Delete the webservice, model, and shut down the compute cluster\n",
        "aci_service.delete()\n",
        "model.delete()\n",
        "amlcompute_target.delete()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1686292250222
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Submission Checklist**\n",
        "- I have registered the model.\n",
        "- I have deployed the model with the best accuracy as a webservice.\n",
        "- I have tested the webservice by sending a request to the model endpoint.\n",
        "- I have deleted the webservice and shutdown all the computes that I have used.\n",
        "- I have taken a screenshot showing the model endpoint as active.\n",
        "- The project includes a file containing the environment details.\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {}
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}